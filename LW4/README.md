> # 2 Налаштування гіперпараметрів дерева
> 
> 1.  Створіть генератор розбиття, який перемішує вибірку перед створенням блоків (shuffle=True). Число блоків n_splits дорівнює >5 . Вкажіть параметр random_state для відтворення результатів. Наприклад:
`kf = KFold(n_splits=5, shuffle=True, random_state=42)`

> 2. Здійсніть крос-валідацію моделі для підбору гіперпараметрів: максимальна глибина дерева max_depth;мінімальна кількість об’єктів для розбиття у внутрішній вершині min_samples_split; мінімальна кількість об’єктів у аркуші min_samples_leaf; максимальна кількість ознак, що розглядаються при пошуку кращого розбиття max_features.
> Використовуйте GridSearchCV. Інтервали зміни гіперпараметрів задайте самостійно.

Отримали: 

```
Точність класифікації Дерева рішень (accuracy): 0.8720
Найкращі параметри: {'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}
Точність GridSearchCV : 0.8997
```

### Висновки

**Оптимальні гіперпараметри:**
- **max_depth=3**: Невелика глибина дерева допомагає уникнути перенавчання.
- **max_features=None**: Використовуються всі доступні ознаки, що забезпечує максимальну інформативність.
- **min_samples_leaf=1**: Кожен лист містить щонайменше один об'єкт.
- **min_samples_split=2**: Для поділу вузла потрібно щонайменше два об'єкти.

**Результати:**
- Точність моделі на тестових даних склала **89.97%**.

**Аналіз:**
- Модель демонструє хорошу узгодженість із даними, без ознак перенавчання.
- Використання всіх ознак дозволяє досягти високої інформативності та точності.

---


> Побудуйте валідаційні криві (залежність метрики від значень гіперпараметрів). Зробіть висновки.

![image](https://github.com/user-attachments/assets/e31dffee-f26c-40ae-be2b-5464a8eed0da)

![image](https://github.com/user-attachments/assets/9a2eda70-18dc-4760-9414-2e9119f5d75f)

![image](https://github.com/user-attachments/assets/e505d2da-cb09-46fe-ad0e-f3941ce45c47)

### Висновки

На основі трьох графіків можна зробити такі висновки:

1. **max_depth (глибина дерева):**
   - Чим більша глибина дерева (`max_depth`), тим краще модель адаптується до навчальної вибірки (accuracy для навчання збільшується).
   - Проте на тестовій вибірці спостерігається зниження точності з ростом глибини, що свідчить про **перенавчання**. 
   - Оптимальна глибина знаходиться в діапазоні 5–10, де баланс між навчальною та тестовою вибіркою кращий.

2. **min_samples_split (мінімальна кількість зразків для розбиття вузла):**
   - Збільшення значення `min_samples_split` зменшує точність навчальної вибірки, оскільки модель стає менш складною.
   - Точність тестової вибірки злегка зростає при підвищенні `min_samples_split`, що свідчить про зменшення переобучення.
   - Значення `min_samples_split` близько 4–5 виглядає оптимальним.

3. **min_samples_leaf (мінімальна кількість зразків у листі):**
   - При збільшенні `min_samples_leaf` точність на навчальній вибірці зменшується, але на тестовій вибірці поступово зростає.
   - Це також вказує на зменшення переобучення, і значення `min_samples_leaf` в межах 4–6 є оптимальним компромісом.

**Загальний висновок:** 
- Для досягнення оптимальної точності потрібно налаштувати параметри:
  - **max_depth** =3,
  - **min_samples_split** =20,
  - **min_samples_leaf** =10.
- Збільшення складності дерева (глибина) чи зменшення мінімальної кількості зразків у вузлах може погіршити точність через перенавчання.

--- 

> 4. Побудуйте графічно отримане дерево. Оцініть важливість ознак за допомогою атрибуту feature_importances_.
> 
> 5. Сформулюйте висновки.

![image](https://github.com/user-attachments/assets/416dcd78-6df1-4717-a978-22fdd3e2e6ae)
![image](https://github.com/user-attachments/assets/84d1eb50-942c-4c8c-a4db-96183ae31b43)

### Висновки на основі аналізу дерева та важливості ознак

1. **Аналіз структури дерева**
   - Модель використала лише кілька найбільш важливих ознак для поділу, що свідчить про їх значний вплив на результат.
   - Основні вузли дерева включають:
     - `nr.employed`: ключова змінна, яка була використана для першого розбиття.
     - `cons.conf.idx`, `pdays`, `euribor3m`: ці ознаки також часто зустрічаються у головних розгалуженнях дерева.
   - Глибина дерева залишається обмеженою, що допомагає зменшити ризик перенавчання.

2. **Аналіз важливості ознак**
   - Найважливіша ознака: 
     - `nr.employed`, яка має найвищий вплив.
   - Важливі, але другорядні ознаки:
     - `pdays` і `cons.conf.idx`.
   - Менш значущі, але помітні ознаки:
     - `month_oct`, `euribor3m`, `contact_telephone`.
   - Інші ознаки мають незначний вплив, тому їх можна буде виключити без втрати точності моделі.

---
---

> # 3  Випадковий ліс
> ---
> 1. Побудуйте модель випадкового лісу (Random Forest) для вашої задачі з гіперпараметрами за замовчуванням та оцініть якість моделі на відкладеній вибірці.

Результат: 
```

Random Forest:        0.8993

=== Звіт для Random Forest ===
              precision    recall  f1-score   support

           0       0.91      0.98      0.95     10968
           1       0.65      0.23      0.34      1389

   macro avg       0.78      0.61      0.64     12357
weighted avg       0.88      0.90      0.88     12357
```

Аналіз моделі випадкового лісу  

1. **Загальна ефективність моделі**  
Модель має точність 89.28%. Вона чудово справляється з класифікацією основного класу ("No"), але її продуктивність для рідкісного класу ("Yes") залишається низькою.  

2. **Результати для класу "No"**  
- **Точність (Precision)**: 0.92 — модель рідко помиляється при прогнозуванні цього класу.  
- **Повнота (Recall)**: 0.97 — майже всі об’єкти класу "No" правильно визначаються.  
- **F1-score**: 0.94 — хороший баланс між точністю та повнотою.  

3. **Результати для класу "Yes"**  
- **Точність (Precision)**: 0.54 — значна кількість помилкових передбачень для цього класу.  
- **Повнота (Recall)**: 0.29 — модель пропускає більшість об’єктів класу "Yes".  
- **F1-score**: 0.38 — низький загальний показник через слабку точність і повноту.  

4. **Середні значення метрик**  
- **Середнє по класах (Macro average)**:  
  - **F1-score**: 0.66 — усереднений показник для обох класів, не враховуючи дисбаланс.  
- **Зважене середнє (Weighted average)**:  
  - **F1-score**: 0.88 — середній показник, скоригований на частку кожного класу в даних.  

5. **Ключові висновки**  
Модель добре працює з основним класом ("No"), однак її продуктивність для класу "Yes" залишає бажати кращого. Дисбаланс у розподілі класів значно впливає на результати. Для задач, де критично важливо коректно класифікувати клас "Yes", модель потребує додаткової оптимізації.

---

> 2. Здійсніть підбір гіперпараметрів моделі: кількість дерев n_estimators; максимальна глибина дерева max_depth; мінімальна кількість об’єктів для розбиття у внутрішній вершині min_samples_split; мінімальна кількість об’єктів у аркуші min_samples_leaf; максимальна кількість ознак, що розглядаються при пошуку кращого розбиття max_features.

```
param_ranges = {

    "max_depth": [3, 5, 10, 15, 20, None],
    "min_samples_split": [2, 3, 4, 5], 
    "n_estimators": [10, 20, 30, 65, 80],
}
```

Отримали результатом значення: 0.7595 , або ж 75.95% . Тобто можемо зробити з цього висновок, що для нашої моделі метод Випадкового лісу є значно кращим варіантом, але знову ж таки не ідеальним.

---

> 3. Побудуйте валідаційні криві для кожного з гіперпараметрів

![image](https://github.com/user-attachments/assets/e50663da-0414-4df5-84d3-103f7067ffd7)

![image](https://github.com/user-attachments/assets/2167cfd5-9abe-4687-b438-a9f57653ec42)

![image](https://github.com/user-attachments/assets/32c55939-bc47-49ce-b338-af57534e448d)

![image](https://github.com/user-attachments/assets/31bab2dc-b317-4c17-8307-b71da51d9afd)


Висновки:

1. **Вплив параметра `max_depth`**  
  - **Навчальна вибірка**: Точність зростає зі збільшенням max_depth, оскільки більш глибокі дерева краще пристосовуються до даних.  
  - **Тестова вибірка**: Точність досягає піку при max_depth у межах 5–10, а потім знижується через перенавчання.  

**Висновок**: Оптимальне значення max_depth — 5–10 для забезпечення балансу між адаптацією до даних і узагальненням.  

2. **Вплив параметра `min_samples_split`**  
  - **Навчальна вибірка**: Зі збільшенням min_samples_split точність знижується, оскільки дерево стає менш складним.  
  - **Тестова вибірка**: Точність стабільна (~0.9), що свідчить про меншу залежність тестової вибірки від цього параметра.  

**Висновок**: Значення min_samples_split > 3–4 допомагає уникнути перенавчання.  


3. **Вплив параметра `n_estimators`**  
  - **Навчальна вибірка**: Точність зростає, але після 50 дерев приріст стає незначним.  
  - **Тестова вибірка**: Точність стабільна, але нижча за навчальну, що може свідчити про недостатню узагальненість.  

**Висновоак**: Використання n_estimators ≥ 50 є оптимальним.  

4. **Вплив параметра `max_features`**  
  - **Навчальна вибірка**: Найвища точність при max_features=None, проте це може спричинити перенавчання. Зменшення max_features (до sqrt або log2) знижує точність, але покращує узагальнення.  
  - **Тестова вибірка**: Точність стабільна незалежно від max_features, але розрив між навчальною і тестовою вибірками зменшується при зменшенні цього параметра.  

**Висновок**: Використання max_features=sqrt або log2 допомагає збалансувати точність і час навчання.  

**Загальний висновок**  
Для оптимізації моделі RandomForestClassifier:  
  - **max_depth**: 5–10  
  - **min_samples_split**: 3–4  
  - **n_estimators**: ≥ 50  
  - **max_features**: sqrt або log2  

---

> 4. Оцініть важливість ознак цієї моделі. Візуалізуйте топ-10 найкорисніших ознак за допомогою стовпчастої діаграми.

![image](https://github.com/user-attachments/assets/951ce514-ae37-47a3-b087-d4879100f51a)

### Висновки щодо впливу ознак у моделі Random Forest:  
- Ознаки, які характеризують клієнта (наприклад, age, housing, loan), мають суттєвий вплив на результати моделі.  
- Економічні показники (euribor3m, cons.conf.idx, cons.price.idx) відіграють важливу роль у передбаченнях.  
- Фактори, пов’язані з результатами маркетингових кампаній (campaign, poutcome_success), також впливають на модель, але їхній вплив є дещо менш значущим.  
