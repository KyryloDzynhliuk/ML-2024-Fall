<h1> Метричні методи машинного навчання </h1>

<h2>1) Методи найближчих сусідів</h2>

**У цій частині роботи ви:**

<li>навчитеся готувати дані до побудови моделі (попередня обробка, або препроцесинг даних);</li>
<li>ознайомитесь з методами найближчих сусідів для задач класифікації та регресії, реалізованими у бібліотеці scikit-learn ; </li>
<li>навчитеся оцінювати якість моделі за допомогою відкладеної вибірки.</li>

<h3>Вказівки до виконання</h3>

**1. Підключіться до набору даних на Kaggle:
      • Варіант 3: Bank marketing;
Розберіться у тому, як влаштований ваш датасет і яка постановка задачі.**

**2. Оберіть цільову ознаку (target). Яка із задач навчання з учителем розглядається - класифікація чи регресія?**

Датасет містить інформацію про банківські маркетингові кампанії і використовується для прогнозування підписки клієнтів на строкові депозити.
`df = pd.read_csv('D:/Machine Learning Course/LW3/bank--additional-full.csv', sep=';')
print(f'Info about the dataframe:\n{df.info()}')
print(f'First five rows of the dataframe:\n{df.head()}')
print(f'Shape of data:\n{df.shape}')
`
Виведені дані підтверджують, що в датасеті є як числові, так і категоріальні змінні. Зазначимо колонка 'y' — це цільова змінна, яка вказує на підписку на строковий депозит (так чи ні). 
Це завдання є задачею класифікації, оскільки ми хочемо передбачити одну з **двох** категорій на основі інших характеристик.

**3. Яким є розподіл значень target-змінної? Побудуйте відповідну візуалізацію. Про-
коментуйте результат.**

![Таргет змінна](https://github.com/user-attachments/assets/08e839a4-4d27-4fd0-8c42-a9e33686ca2f)

На графіку видно, що кількість клієнтів, які погодилися на підписку по депозиту, більша за кількість тих, хто відмовився. Це означає, що в даних присутній певний дисбаланс. Можемо з цього зробити висноков, що в нас може бути недостатня точність для менш представленого класу, адже дисбаланс може вплтвати на якість моделей класифікації. Так може відбутись, тому що більшість стандартних алгоритмів схильні прогнозувати частіший клас.


**4. Проведіть необхідну попередню обробку даних (preprocessing). Для побудови моделей за допомогою метричних методів усі ознаки мають бути закодовані числами. Корисними будуть такі методи бібліотеки Pandas:**

- `map()` — **для перекодування категоріальної змінної числовими мітками;**

- `get_dummies()` — **для створення декількох бінарних ознак на основі категоріальної.**

**Також може знадобитися масштабування даних (scaling). Скористайтеся класом бібліотеки Scikit-learn.**


```
df['y'] = df['y'].map({'yes': 1, 'no': 0})


categorical_columns = df.select_dtypes(include=['object']).columns
df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

scaler = StandardScaler()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns

df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

```


Перекодування категоріальних змінних за допомогою map() і get_dummies().
Масштабування числових змінних для нормалізації значень.


**5. Розбийте набір даних на навчальну та валідаційну (тестову) вибірки за допомогою
методу train_test_split .**

```
X = df.drop('y', axis=1)
y = df['y']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
Датасет розділений на 80% навчальну та 20%  на тестову вибірки

**6. Навчіть алгоритм класифікації kNeighborsClassifier або регресії
KNeighborsRegressor . Оцініть якість кожної моделі на валідаційній вибірці за
допомогою**
-` accuracy_score `для класифікації;
- `mean_squared_error` для регресії.
**Порівняйте результати та зробіть висновки.**

```
clf = KNeighborsClassifier(n_neighbors=5)
clf.fit(X_train, y_train)
y_pred_class = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred_class)
print(f'Точність класифікаційної моделі (accuracy): {accuracy:.4f}')


reg = KNeighborsRegressor(n_neighbors=5)
reg.fit(X_train, y_train)
y_pred_reg = reg.predict(X_test)
mse = mean_squared_error(y_test, y_pred_reg)
print(f'Середньоквадратична похибка регресійної моделі (MSE): {mse:.4f}')
```

Розмір навчальної вибірки: X_train: (1048, 44), y_train: (1048,)
Розмір тестової вибірки: X_test: (262, 44), y_test: (262,)

Точність класифікаційної моделі (accuracy): 0.6756 достатньо хороший для деяких бізнес-завдань, але її можна покращити за допомогою інших методів. 


<h2>2 Налаштування оптимальної кількості найближчих сусідів у методі kNN</h2>

У цій частині роботи ви навчитеся налаштовувати параметр `n_neighbors `алгоритму kNN за допомогою перехресної перевірки (крос-валідації).

<h3>Вказівки до виконання</h3>

**1. Створіть генератор розбиття, який перемішує вибірку перед створенням блоків ( shuffle=True ). Число блоків n_splits дорівнює 5. Вкажіть параметр random_state для відтворення результатів.** 
```Наприклад:
kf = KFold(n_splits=5, shuffle=True, random_state=42)
```
**Знайдіть показник якості моделі kNN на крос-валідації. Подумайте, чи прийнятне використання вашої міри (метрики) якості у цій задачі? При необхідності перерахуйте якість за допомогою іншої метрики з списку.**

**2. Здійсніть крос-валідацію моделі при числі сусідів k ∈ [1;50]. Використовуйте GridSearchCV . При якому k якість вийшла найкращою? Чому дорівнює ця оцінка якості? Побудуйте графік значень метрики залежно від k( matplotlib.pyplot.plot() ).**

```
kf = KFold(n_splits=5, shuffle=True, random_state=42)

knn = KNeighborsClassifier()
param_grid = {'n_neighbors': range(1, 51)}

grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=kf, scoring='accuracy')
grid_search.fit(X, y)

best_k = grid_search.best_params_['n_neighbors']
best_score = grid_search.best_score_
print(f'Найкраще значення k: {best_k}')
print(f'Оцінка якості при найкращому k: {best_score:.4f}')

k_values = range(1, 51)
scores = grid_search.cv_results_['mean_test_score']

plt.plot(k_values, scores, marker='o')
plt.xlabel('Кількість сусідів (k)')
plt.ylabel('Точність перехресної перевірки')
plt.title('Accuracy vs. Кількість сусідів (k) для kNN')
plt.grid()
plt.show()

```

**KFold**  забезпечує відтворюваність.
**GridSearchCV** записує метричні оцінки для кожно з k від 1 до 50.

**Найкраще значення k: 46**  - це оптимальне значення кількості сусідів, яке було знайдено за допомогою крос-валідації. Це вказує на те, що модель працює найкраще при 46 найближчих сусідах.

**Оцінка якості при найкращому k: 0.7076**  - це точність класифікації на крос-валідаційних даних при найкращому k. Точність зросла порівняно з результатом на тестовій вибірці (0.6756), що свідчить про те, що модель може бути ще більш оптимізована для цього набору даних. 

![Figure_2](https://github.com/user-attachments/assets/227790cc-8678-475a-8e41-9395e81d2e2a)

Бачимо, що зі збільшенням сусідів ми підходимо до доволі непоганого показника Accuracy, що є на даному діапазоні (до 50) гарною ідеєю без Underfitting-а.


<h2>3 Вибір метрики у методі kNN</h2>

**Головним параметром будь-якого метричного алгоритму є функція відстані (метрика), що використовується для виміру подібності між об’єктами. Можна використовувати стандартний варіант (наприклад, евклідову метрику), але більш ефективним варіантом є підбір метрики під конкретну задачу. Один з підходів — використання тієї ж евклідовоїметрики, але з вагами: кожній координаті ставиться у відповідність певний коефіцієнт; чим він більший, тим вищий внесок ознаки у підсумкову відстань. Ваги налаштовуються з метою оптимізації якості на відкладеній вибірці. Інший підхід, про який і йтиметься у цій частині роботи — вибір метрики з деякого класу метрик. Ми візьмемо за основу метрику Мінковського.**


<h3>Вказівки до виконання</h3>

**1. Переберіть різні варіанти значень параметра p по сітці від 1 до 10 з таким кроком,
щоб всього було протестовано 20 варіантів (зручно використовувати функцію
numpy.linspace ).**

![Figure_3](https://github.com/user-attachments/assets/6ba60c65-0364-41ff-878c-81ddca3f03c6)


**Використовуйте KNeighborsClassifier або KNeighborsRegressor з опти-
мальним значенням n_neighbors , знайденим раніше. Задайте опцію weights='distance' — цей параметр додає в алгоритм ваги, що залежать від відстані до найближчих сусідів. В якості метрики якості знову використовуйте accuracy . Якість оцінюйте за допомогою крос-валідації по 5 блоків.**

**2. Визначте, за якого p якість на крос-валідації виявилася оптимальною. Зверніть увагу, що cross_val_score повертає масив показників якості блоків; необхідно максимізувати середнє цих показників.**

```
p_values = np.linspace(1, 10, 20)
param_grid = {'n_neighbors': [best_k], 'p': p_values}
knn = KNeighborsClassifier()
grid_search_p = GridSearchCV(estimator=knn, param_grid=param_grid, cv=kf, scoring='accuracy')
grid_search_p.fit(X, y)
best_p = grid_search_p.best_params_['p']
best_p_score = grid_search_p.best_score_

print(f'Найкраще значення p: {best_p:.4f}')
print(f'Оцінка якості при найкращому p: {best_p_score:.4f}')
```

У цьому коді ми оптимізували параметр p для метрики Мінковського, використовуючи kNN з weights='distance', а також виконали крос-валідацію для різних значень p.

**Найкраще значення p: 2.8947** - оптимальний параметр для метрики Мінковського. Знайшли через крос-валідацію. Визначає, наскільки сильно враховуються відстані між точками в різних ознаках.
**Оцінка якості при найкращому p: 0.7099** - це точність моделі при оптимальному значенні p. Це показує незначне підвищення точності порівняно з оптимальним значенням k, що дає нам зрозуміти правильність вибору параметра метрики.
```

best_p_idx = np.argmax(mean_accuracies)
best_p = p_values[best_p_idx]
best_p_accuracy = mean_accuracies[best_p_idx]

print(f'Оптимальне значення p: {best_p:.4f}')
print(f'Максимальна середня точність для p={best_p:.4f}: {best_p_accuracy:.4f}')
```

Вибір оптимального p виявився найкращим при значенні p=1.0, що підтвердилося найбільшою середньою точністю на крос-валідації.

```
knn_weighted = KNeighborsClassifier(n_neighbors=best_k, weights='distance')
cv_scores = cross_val_score(knn_weighted, X, y, cv=5, scoring='accuracy')

print(f'Крос-валідаційна точність для KNN з вагами по відстані: {cv_scores}')
print(f'Середня точність на крос-валідації: {cv_scores.mean():.4f}')
print(f'Стандартне відхилення точності: {cv_scores.std():.4f}')



p_values = np.linspace(1, 10, 20)
mean_accuracies = []
for p in p_values:
    
    knn_weighted = KNeighborsClassifier(n_neighbors=best_k, p=p, weights='distance')
    cv_scores = cross_val_score(knn_weighted, X, y, cv=5, scoring='accuracy')
    mean_accuracy = cv_scores.mean()
    mean_accuracies.append(mean_accuracy)

best_p_idx = np.argmax(mean_accuracies)
best_p = p_values[best_p_idx]
best_p_accuracy = mean_accuracies[best_p_idx]

print(f'Оптимальне значення p: {best_p:.4f}')
print(f'Максимальна середня точність для p={best_p:.4f}: {best_p_accuracy:.4f}')
```

**Крос-валідаційна точність для KNN з вагами по відстані: [0.45038168 0.20229008 0.56870229 0.63358779 0.64122137]
Оцінка якості при найкращому p: 0.7099
Оцінка якості при найкращому p: 0.7099
Крос-валідаційна точність для KNN з вагами по відстані: [0.45038168 0.20229008 0.56870229 0.63358779 0.64122137]
Оцінка якості при найкращому p: 0.7099
Оцінка якості при найкращому p: 0.7099
Оцінка якості при найкращому p: 0.7099
Крос-валідаційна точність для KNN з вагами по відстані: [0.45038168 0.20229008 0.56870229 0.63358779 0.64122137]
Крос-валідаційна точність для KNN з вагами по відстані: [0.45038168 0.20229008 0.56870229 0.63358779 0.64122137]
Середня точність на крос-валідації: 0.4992
Стандартне відхилення точності: 0.1635
Стандартне відхилення точності: 0.1635
Оптимальне значення p: 9.5263
Максимальна середня точність для p=9.5263: 0.5458**


- Середня точність 0.4992 та максимальна точність 0.5458 свідчать про слабку ефективність моделі.
- Велике стандартне відхилення точності (0.1635) та різниця між фолдами в крос-валідації можуть вказувати на нестабільність моделі на різних підмножинах даних. 
- Значення p = 9.5263 є оптимальним, але модель не здатна значно покращити точність навіть при цьому параметрі. Тобто ми можемо зробити висновок, що метрика Мінковського є не найкращоб метрикою для нашої задачі.

Легко проаналізувати це на графіку:
![Figure_4](https://github.com/user-attachments/assets/9ef50092-16cb-497b-b164-d156c08d6dea)
p = 1 відповідає Манхеттенській відстані
p = 2 відповідає Евклідовій відстані 
p > 2 дає більший акцент на далекі точки.

Бачимо, що точність спочатку зростає, а потім стабілізується, але з легкими коливаннями. Це у свою чергу означає, що є оптимальний діапазон значень p, при якому модель дає кращі результати.
На графіку є  пік, який означає, що саме це значення p дає найкращу точність на крос-валідації. (у нашому випадку це p = 9.5263, як ми отримували в обчисленнях вище і як можна помітили на графіку). Оскільки максимальна точність для p = 9.5263 лише 0.5458, це вказує на те, що модель все ще не досягає хороших результатів :( .

<h3>Експериментальний метод</h3>

```
from sklearn.neighbors import NearestCentroid
from sklearn.model_selection import cross_val_score

centroid_clf = NearestCentroid()
cv_scores_centroid = cross_val_score(centroid_clf, X, y, cv=5, scoring='accuracy')

print(f'Крос-валідаційна точність для NearestCentroid: {cv_scores_centroid}')
print(f'Середня точність на крос-валідації для NearestCentroid: {cv_scores_centroid.mean():.4f}')
print(f'Стандартне відхилення точності для NearestCentroid: {cv_scores_centroid.std():.4f}')
```

**Крос-валідаційна точність для NearestCentroid: [0.3778626  0.3740458  0.64122137 0.63358779 0.64503817]
Середня точність на крос-валідації для NearestCentroid: 0.5344
Стандартне відхилення точності для NearestCentroid: 0.1294**   


Результати крос-валідації демонструють значні коливання в точності. А отже NearestCentroid не є найкращим методом для даного типу задачі або набору даних.

Середня точність в 53.44% вказує на те, що модель, ймовірно, не навчається на даних ефективно, оскільки в ідеальному випадку точність повинна бути вищою від 70-80%.

Велике стандартне відхилення свідчить про те, що точність моделі варіюється між фолдами. Це може означати, що модель не стабільна або вона занадто чутлива до особливостей даних.


Висновки:
Середня точність на крос-валідації: 0.8741 — гарний результат, хоча трохи нижчий, ніж у KNN.
Стандартне відхилення: 0.0520 — невелике, що свідчить про стабільність моделі.
Крос-валідаційна точність: [0.887, 0.891, 0.902, 0.918, 0.772] — менше варіацій у порівнянні з KNN.
